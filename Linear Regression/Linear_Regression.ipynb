{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Содержание:**\n",
    "\n",
    "1. Математическая постановка задачи\n",
    "\n",
    "2. Решение задачи\n",
    "\n",
    "3. Регуляризация - борьба с переобучением\n",
    "\n",
    "4. Какое представление данных будет наилучшим, как их преобразовать\n",
    "\n",
    "5. Реализация модели на numpy\n",
    "\n",
    "6. Изучение готовых реализаций из библиотек\n",
    "\n",
    "7. Обучение разных реализаций и сравнение\n",
    "\n",
    "8. Как контролировать обучение модели\n",
    "\n",
    "9. Как посмотреть важность признаков. Что ещё можно полезного извлечь из обученной модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Математическая постановка задачи**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача регрессии:** на вход подаётся вектор *$x ∈ ℝ^n$*. На выходе пораждается скалярное значение *$y ∈ ℝ$*. Линейная регрессия решает такую задачу\n",
    "Обозначим *$\\hat{y}$* – значение *$y$*, предсказанное моделью. Определим результат модели в виде *$\\hat{y} = w^T*x$*, где *$w ∈ ℝ^n$* – вектор параметров. *$w$* - набор весов описывающих влияние отдельных признаков на результат предсказания.\n",
    "\n",
    "Таким образом задача формулируется так: *Предсказать $y$ по $x$, вычислив значение $\\hat{y} = w^T*x$*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также сформулировать задачу можно с помощью оценки максимального правдоподобия, но здесь такой подход подробно рассматриваться не будет\n",
    "\n",
    "![Alt text](image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Решение задачи**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для подбора таких *$w^T$*, чтобы *$\\hat{y}$* было как можно ближе к истинным значениям *$y$*, нужно ввести меру качества для *$w^T$*\n",
    "\n",
    "Пусть имеется матрица плана с *$m$* примерами, которые мы будем использовать не для обучения, а только для оценки качества работы модели. Имеется также вектор меток, содержащий правильные значения *$y$* для каждого из этих примеров. Поскольку  этот набор данных будет использоваться только для контроля качества, назовем его тестовым набором. Обозначим матрицу плана *$X_{test}$*, а вектор меток регрессии – *$y_{test}$*. \n",
    "\n",
    "Один из способов измерения качества модели – вычислить среднеквадратическую ошибку модели на тестовом наборе. Если вектор *$y_{test}$* содержит предсказания модели на тестовом наборе, то среднеквадратическая ошибка определяется по формуле *$MSE_{test} = \\frac{1}{m} \\sum_{i=1}^{m}(\\hat{y_{i}} - y_{i})^2$*\n",
    "\n",
    "Эта мера ошибки обращается в *$0$*, когда *$\\hat{y}_{test}$* = *$y_{test}$*. \n",
    "\n",
    "Кроме того, *$MSE_{test} = \\frac{1}{m} \\mid\\mid \\hat{y}_{test} - y_{test} \\mid\\mid^2_{2}$*, поэтому ошибка тем больше, чем больше евклидово расстояние между предсказаниями и метками"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы должны спроектировать алгоритм машинного обучения, который улучшает веса *$w$* таким образом, что *$MSE_{test}$* уменьшается по мере того, как алгоритм получает новый опыт, наблюдая обучающий набор *$(X_{train}, y_{train})$*. Интуитивно понятный способ добиться этой цели – минимизировать среднеквадратическую ошибку на обучающем наборе, *$MSE_{train}$*. Для минимизации *$MSE_{train}$* нужно просто приравнять градиент к *$0$* и решить получившееся уравнение:\n",
    "\n",
    "*$\\triangledown_{w} MSE_{test} = 0$* *$\\rArr$* *$\\triangledown_{w} \\frac{1}{m} \\mid\\mid \\hat{y}_{test} - y_{test} \\mid\\mid^2_{2} = 0$* *$\\rArr$* *$\\triangledown_{w} (X_{train}*w - y_{train})^T(X_{train}*w - y_{train}) = 0$* *$\\rArr$* *$\\triangledown_{w}(w^T*X^T*X*w - 2*w^T*X^T*y + y^T*y) = 0$* \n",
    "\n",
    "*$\\rArr$*  $\\nabla\\mid\\mid X*w - y \\mid\\mid^2_{2} = 2*X^T*X*w - 2*X^T*y = 0$\n",
    "\n",
    "$X^T*X*w = X^Ty$\n",
    "\n",
    "$w = y*X^T(X^T*X)^{-1}$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако это решение считается неоптимальным, кроме того, для других моделей аналитического решения может и не существовать. К счастью, найти такой вектор *w*, при котором функция потерь минимальна, хоть и приближенно, позволяет градиентный спуск и его модификации.\n",
    "\n",
    "*   обращение матрицы имеет сложность O($n^3$)\n",
    "*   матрица $X^T*X$ может оказаться вырожденной, и тогда обращение будет невозможным\n",
    "*   если заменить функционал MSE на другой, то решение для $w$, вероятнее всего, не получится"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Градиентный спуск**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*$w^{k} = w^{k-1} - lr*\\triangledown_{w_{k-1}}(L)$* Где lr - learning rate - длина шага, являкется гиперпараметром, задаётя разработчиком, может быть функцией.\n",
    "\n",
    "![Alt text](image-10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Простой градиентный спуск имеет множество недостатков, поэтому были придуманы его модификации, которые будут рассмотрены в реализации технологий глубокого обучения, а пока опишу их кратко.\n",
    "\n",
    "![Alt text](image-14.png)\n",
    "\n",
    "![Alt text](image-15.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Оценка решения задачи линейной регрессии - метрики и функции потерь**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Функция потерь:** Функция потерь определяет, насколько хорошо модель справляется с текущей задачей обучения. Ее цель - создать градиент, который модель будет использовать для обновления своих параметров в процессе обучения. Функция потерь должна быть дифференцируемой и ее минимизация приводит к улучшению качества модели.\n",
    "\n",
    "**Метрика:** Метрика, с другой стороны, представляет собой способ оценки производительности модели после обучения. Метрика измеряет, насколько хорошо модель работает на тестовых данных или в реальных условиях. Метрика может быть не дифференцируемой и не использоваться в процессе оптимизации параметров модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE также является и метрикой, по которой оценивают результат работы линейной регрессии. Кроме метрики MSE есть множество других метрик, просто MSE наиболее популярная. И хотя MSE дифференцируемая, выпуклая и обусловленная вероятностным подходом к решению данной задачи, у неё есть ряд проблем. Рассмотрим другие оценки (функции потерь по совместительству) и сравним между собой"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*MSE = $\\frac{1}{n} \\sum_{i=1}^{n}(\\hat{y_{i}} - y_{i})^2 → min$* : плохо интерпретируема, так как возвращает возведённую в квадрат оценку искомой величины"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*RMSE = $\\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(\\hat{y_{i}} - y_{i})^2} → min$* : RMSE решает проблему квадрата величины, но всё ещё эта метрика остаётся плохо интерпертируемой. Например RMSE = 500 будет считаться очень плохим решением задачи, если целевая переменная расположена в промежутке от 0 до 200. Но такое значение ошибки будет считатья великолепным, если целевая переменная расположена в промежутке от 10000 до 1000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*$R^2 = 1 - \\frac{\\sum_{i=1}^{n}(\\hat{y_{i}} - y_{i})^2}{\\sum_{i=1}^{n}({y_{i}} - \\bar{y_{i}})^2}$, где $\\bar{y_{i}}$* - среднее значение целевой переменной.\n",
    "Если *$\\hat{y_{i}} = y_{i}$*, то *$R^2$* равен *1* - это означает, что модели идеальна.\n",
    "\n",
    "Если модель выдаёт постоянное значение, равное среднему значению целевой переменной на выборке, то *$R^2$* будет равен *0*\n",
    "\n",
    "Модель считается приемлемой, если её *$R^2$* лежит в пределах од 0 до 1. И чем ближе к единице тем лучше\n",
    "\n",
    "Как видно, эта метрика хорошо интерпретируема. И всё-таки, для разных задач значение R^2 можно интерпертировать по-разному."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*MAE = $\\frac{1}{n}\\sum_{i=1}^{n}\\mid \\hat{y_{i}} - y_{i} \\mid → min$* : Немного более устойчива к выбросам в данных. Сложна для градиентной оптимизации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](image-5.png) - сравнение MAE и MSE в выборке с выбросом для двух моделей. MSE уменьшает большую ошибку - ошибку на выбросе. MAE не приоретезирует ошибки на выбросах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*HUBER LOSS* - ![Alt text](image-6.png) - компромисс между MSE и MAE. Не имеет второй производной. Дельта определяет, какие данные считаются выбросами, а какие - нет.\n",
    " \n",
    "![Alt text](image-7.png) - график Huber loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Log-cosh = $log(cosh(a-y))$* - имеет вторую производную, похожа на HUBER LOSS.\n",
    "\n",
    "![Alt text](image-8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*MSLE = $(log(a+1) - log(y+1))^2$* - работает, если прогнозы модели и целевая переменная неотрицательны.  Она может быть полезной, когда важно учитывать относительные изменения величин, а не абсолютные значения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*MAPE = $\\mid\\mid \\frac{y-a}{a}\\mid\\mid$* - MAPE измеряет ошибку в процентах относительно истинных значений целевой переменной. Она показывает относительную точность прогнозов. Минус - несимметрична.\n",
    "\n",
    "![Alt text](image-9.png)\n",
    "\n",
    "Пример: Прогноз продаж товаров: Предположим, вы управляете магазином и хотите прогнозировать ежедневные продажи различных товаров. В этой задаче MAPE может помочь вам измерить точность в процентах, насколько ваши прогнозы близки к фактическим продажам.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*SMAPE*, или Симметричное среднее абсолютное процентное отклонение (Symmetric Mean Absolute Percentage Error), это метрика оценки точности прогнозов в задачах прогнозирования временных рядов и прогнозирования, особенно в сферах, где важна относительная оценка ошибки в процентах. SMAPE измеряет процентное отклонение между истинными значениями и прогнозами модели.\n",
    "\n",
    "![Alt text](image-13.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Квантильная функция потерь (Quantile Loss)* - позволяет регулировать штраф за занижение и повышение прогноза. max(q * (y-y_pred), (1-q) * (y_pred-y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция потерь подбирается под особенности задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Регуляризация - борьба с переобучением**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В зависимости от факторов таких как размер датасета, , модель может показывать очень хорошие результаты на тренировочной выборке, но на тестовой показывать неудовлетворительные результаты. Такакя ситуация называется переобучением. При переобучении модель просто подстраивается под данные обучающей выборки, а не находит закономерности в данных. \n",
    "\n",
    "![Alt text](image-16.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для борьбы с этой проблемой используется регуляризация. Один из способов - это штрафовать модель за слишком большие веса. Чаще всего для таких целей используют L1 - (Lasso) и L2 - (Ridge)- регуляризации.\n",
    "\n",
    "![Alt text](image-17.png)\n",
    "![Alt text](image-18.png)\n",
    "\n",
    "Лямбда - коэф-т регуляризации, гиперпараметр, задаваемый вручную, подбором."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также существует кобинация L1 и L2, называемая Elastic-Net регуляризацией\n",
    "\n",
    "$\\mid\\mid X*w - y \\mid\\mid^2_{2} + λ*\\mid\\mid w\\mid\\mid_1^2 → min$ - Lasso-регрессия\n",
    "\n",
    "$\\mid\\mid X*w - y \\mid\\mid^2_{2} + λ*\\mid\\mid w\\mid\\mid_2^2 → min$ - Ridge-регрессия\n",
    "\n",
    "$\\mid\\mid X*w - y \\mid\\mid^2_{2} + λ*\\mid\\mid w\\mid\\mid_2^2 + λ*\\mid\\mid w\\mid\\mid_1^2→ min$ - Elastic Net-регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](image-19.png) - изменение весов разными видами регуляризации. Как видно, L1 хороша при отборе признаков, когда из большого кол-ва нужно выбрать самые важные, ведь она зануляет веса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1! На смещение, т.е w0 регуляризация действовать не должна! 2! Чтобы регуляризация работала, признаки при входе в модель должны быть отнормированы!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](image-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](image-1.png) - математическое обоснование L1 и L2 регуляризаций"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](image-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Какое представление данных будет наилучшим, как их преобразовать**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы уже поняли, чтобы модель не переобучилось нужно применять регуляризацию, а для регуляризации нужно подавать отнормированные признаки. Т.е ![Alt text](image-21.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме того, в данных могут быть пропущенные значения, и в зависимотси от данных нужно их заполнить или вовсе удалить.\n",
    "Иногда бывает полезно составлять новые признаки из существующих, а старые удалять, если они коррелируют. (Feature-Engineering)\n",
    "\n",
    "Предобработка данных - очень масштабная тема, поэтому здесь будут изложены краткие принципы.\n",
    "\n",
    "**Предобработка данных:**\n",
    "\n",
    "*   Заполнение пропусков (чаще всего средним значением или медианой)\n",
    "*   Кодировка (OneHotEncoder, LabelEncoder, BinaryEncoder, HelmetEncoder, Backward-Difference Encoder, TargetEncoding ...)\n",
    "*   Масштабирование признаков (StandardDcaler, MinMaxScaler)\n",
    "*   Добавление признаков (полиномиальные признаки, взятие логарифма, квадратного корня, применение тригонометрических функий)\n",
    "*   Удаление выбросов/шума"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Реализация модели**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_LinearRegression:\n",
    "    def __init__(self, lr = 0.01, rate_forgetting = 0.05, iters = 1000, reg_param = 0.1, reg_type = None, loss_fn_type = 'MSE'):\n",
    "        self.lr = lr\n",
    "        self.iters = iters\n",
    "        self.reg_param = reg_param\n",
    "        self.reg_type = reg_type\n",
    "        self.loss_fn_type = loss_fn_type\n",
    "        self.rate_forgetting = rate_forgetting\n",
    "        self.weights = None\n",
    "        self.bias = 0\n",
    "        self.losses = []\n",
    "    \n",
    "    def __loss_fn(self, y, preds):\n",
    "        if self.reg_type == None:\n",
    "            return np.sum((y-preds)**2)\n",
    "        elif self.reg_type in ['l1', 'lasso']:\n",
    "            return np.sum((y - preds)**2) + self.reg_param*np.sum(np.abs(self.weights))\n",
    "        elif self.reg_type in ['l2', 'ridge']:\n",
    "            return np.sum((y - preds)**2) + self.reg_param*np.sum((self.weights)**2)\n",
    "        elif self.reg_type == 'elastic':\n",
    "            return np.sum((y - preds)**2) + self.reg_param*np.sum((self.weights)**2) + (1-self.reg_param)*np.sum(np.abs(self.weights))\n",
    "        else:\n",
    "            raise ValueError(\"Введите 'l1', 'l2', 'lasso', 'ridge', или 'elastic'\")\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        num_samples, num_features = X.shape\n",
    "        self.weights = np.zeros(num_features)\n",
    "        functional_evaluation = (1/num_samples)*__loss_fn(y, X.T*self.weights)\n",
    "        for i in range(self.iters):\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6\n"
     ]
    }
   ],
   "source": [
    "weights = np.array([0,1,3])\n",
    "y = 0.4\n",
    "print(np.sum(np.abs(weights))*y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](image-4.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
